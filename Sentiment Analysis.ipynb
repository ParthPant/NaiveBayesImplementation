{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import collections\n",
    "#import sys\n",
    "#np.set_printoptions(threshold=sys.maxsize)\n",
    "import string\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train.tsv',delimiter='\\t')\n",
    "# data = data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data = data.loc[:109242,:]\n",
    "train_data = data\n",
    "test_data = data.loc[109242:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hasNumbers(inputString):\n",
    "    return any(char.isdigit() for char in inputString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractWords(phrase):\n",
    "    phrase = phrase.lower()\n",
    "    words = phrase.split()\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [w.translate(table) for w in words]\n",
    "    words = [w for w in words if w != \"\" and not hasNumbers(w)]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildVocabulary(phrases):\n",
    "    '''\n",
    "    phrases - a list of phrases from which to build the vocabulary\n",
    "    '''\n",
    "#     print('building Vocabulary')\n",
    "    \n",
    "    all_words = []\n",
    "    vocabulary = []#     phrases = train_data.to_numpy()[:,2]\n",
    "    \n",
    "    \n",
    "    for phrase in tqdm(phrases):\n",
    "        all_words += extractWords(phrase)\n",
    "\n",
    "    for x in tqdm(all_words):\n",
    "        if x not in vocabulary:\n",
    "            vocabulary.append(x)\n",
    "\n",
    "    vocabulary.sort()\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 156060/156060 [00:05<00:00, 27649.31it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████| 1044040/1044040 [01:52<00:00, 9283.40it/s]\n"
     ]
    }
   ],
   "source": [
    "phrases = train_data.to_numpy()[:,2]\n",
    "\n",
    "train_sentiments = train_data.to_numpy()[:,3]\n",
    "test_sentiments = test_data.to_numpy()[:,3]\n",
    "\n",
    "vocabulary = buildVocabulary(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseData(phrases,vocabulary):\n",
    "#     print('Parsing Phrases')\n",
    "    \n",
    "    output = np.zeros([len(phrases),len(vocabulary)],dtype='int32')\n",
    "    missing_wds = 1\n",
    "    iterable = tuple(enumerate(phrases))\n",
    "    \n",
    "    \n",
    "    for i,phrase in tqdm(iterable):\n",
    "        feature = np.zeros(len(vocabulary),dtype='int32')\n",
    "        words = extractWords(phrase)\n",
    "        for word in words:\n",
    "            try:\n",
    "                feature[vocabulary.index(word)] = 1.0\n",
    "            except:\n",
    "                missing_wds += 1\n",
    "        output[i] = feature\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 156060/156060 [11:07<00:00, 233.92it/s]\n"
     ]
    }
   ],
   "source": [
    "parsed_data = parseData(phrases,vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arrangeClasswise(phrases,sentiments):\n",
    "    output = {}\n",
    "    for cls in np.unique(sentiments):\n",
    "        output[cls]=[]\n",
    "        for i,phrase in enumerate(phrases):\n",
    "            if cls == sentiments[i]:\n",
    "                output[cls].append(phrase)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainNaiveBayes(parsed_phrases,sentiments,len_vocab):\n",
    "#     print('Training')\n",
    "    \n",
    "    classes,counts = np.unique(sentiments,return_counts=True)\n",
    "    phi_y = [cnt/len(sentiments) for cls, cnt in tuple(zip(classes,counts))]\n",
    "    phi_x_y = np.zeros([len(classes),len_vocab])\n",
    "    classwise_dict = arrangeClasswise(parsed_phrases,sentiments)\n",
    "    \n",
    "    for cls,cls_set in tqdm(classwise_dict.items()):\n",
    "        phi_x_y[cls] = np.sum(cls_set,axis = 0)   #check this.............\n",
    "        phi_x_y[cls] += 1\n",
    "        phi_x_y[cls] /= (len(classwise_dict[cls])+len(classes))\n",
    "    return phi_y, phi_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 5/5 [01:03<00:00, 12.78s/it]\n"
     ]
    }
   ],
   "source": [
    "phi_y, phi_x_y = trainNaiveBayes(parsed_data,train_sentiments,len(vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.24289953e-01, 1.41302812e-04, 1.41302812e-04, ...,\n",
       "        1.41302812e-04, 1.41302812e-04, 8.47816872e-04],\n",
       "       [2.39716988e-01, 3.66595791e-05, 2.93276633e-04, ...,\n",
       "        3.66595791e-05, 3.66595791e-05, 3.66595791e-05],\n",
       "       [1.34192770e-01, 3.76945984e-05, 1.13083795e-04, ...,\n",
       "        1.75908126e-04, 8.79540628e-05, 1.25648661e-05],\n",
       "       [2.54949593e-01, 6.07312037e-05, 3.03656018e-05, ...,\n",
       "        9.10968055e-05, 6.07312037e-05, 3.03656018e-05],\n",
       "       [3.44045163e-01, 2.17131690e-04, 1.08565845e-04, ...,\n",
       "        1.08565845e-04, 3.25697536e-04, 1.08565845e-04]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_x_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see this.........................\n",
    "def predict(phrases,vocabulary):\n",
    "    class_no = phi_x_y.shape[0]\n",
    "    phrases = np.array(parseData(phrases,vocabulary))\n",
    "    \n",
    "    predictions = np.ones([len(phrases),class_no])\n",
    "    \n",
    "    for p,phrase in enumerate(phrases):\n",
    "        for c in range(class_no):\n",
    "            a = phrase\n",
    "            b =1-phrase\n",
    "            \n",
    "            a = a * phi_x_y[c]\n",
    "            #b = b * (1-phi_x_y[c])\n",
    "            a[a==0] = 1\n",
    "#             s = a+b\n",
    "            p_x_y = np.prod(a)\n",
    "            predictions[p,c] = p_x_y*phi_y[c]\n",
    "        \n",
    "#     predictions*phi_y\n",
    "    output = []\n",
    "    for prediction in predictions:\n",
    "        output.append(np.argmax(prediction))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 781.86it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 3]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = predict(['boring','good movie'],vocabulary)\n",
    "\n",
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
